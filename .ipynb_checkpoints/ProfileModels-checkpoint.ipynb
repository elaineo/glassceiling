{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import site\n",
    "site.getusersitepackages()\n",
    "site.addsitedir('/usr/local/Cellar/python/2.7.10/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "\n",
    "import MySQLdb as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, isdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirs = [ './data/'+f for f in listdir('./data/') if isdir(join('./data/',f)) ]\n",
    "filelist = []\n",
    "for d in dirs:\n",
    "    files = [ d+'/'+f for f in listdir(d) if isfile(join(d+'/',f)) ]\n",
    "    filelist += files\n",
    "#filelist = [ './data/'+f for f in listdir('./data/') if isfile(join('./data/',f)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('files.json','w') as f:\n",
    "    json.dump(filelist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct the dictionary without loading all texts into memory:\n",
    "dictionary = corpora.Dictionary(nltk.word_tokenize(doc.lower()) for doc in get_profiles(filelist))\n",
    "\n",
    "garbage = ['summary', 'experience', 'languages', 'skills', 'education', 'honors']\n",
    "stopwords = nltk.corpus.stopwords.words('english') + garbage\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stopwords\n",
    "             if stopword in dictionary.token2id]\n",
    "    \n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
    "dictionary.compactify() # remove gaps in id sequence after words that were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'our'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus0 = MyCorpus()\n",
    "tfidf = models.TfidfModel(corpus0)\n",
    "corpus = tfidf[corpus0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'blah'\n",
    "corpora.MmCorpus.serialize('%s.mm' % name, corpus)\n",
    "corpus = corpora.MmCorpus('%s.mm' % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#query\n",
    "query = pull_profile('https://www.linkedin.com/in/elaineo')\n",
    "vec_bow = dictionary.doc2bow(nltk.word_tokenize(query.lower()))\n",
    "vec_lsi = lsi[vec_bow] # convert the query to LSI space\n",
    "\n",
    "s = sorted(vec_lsi, key=lambda item: -item[1])\n",
    "# print lsi.print_topic(s[0][0])\n",
    "\n",
    "# perform query\n",
    "sims = index[vec_lsi] # perform a similarity query against the corpus\n",
    "\n",
    "# sort similarities in descending order\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77231"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = similarities.Similarity('%s.index' % name, lsi[corpus], \n",
    "        num_features=corpus.num_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_profiles(files):\n",
    "    for f in files:\n",
    "        with open(f, 'r') as openf:        \n",
    "            x = json.load(openf) \n",
    "            for profile in x['profiles']:\n",
    "                yield profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "     def __iter__(self):\n",
    "        for f in filelist[:10]:\n",
    "            with open(f, 'r') as openf:        \n",
    "                x = json.load(openf) \n",
    "                for profile in x['profiles']:\n",
    "                    t = nltk.word_tokenize(profile.lower())\n",
    "                    yield dictionary.doc2bow(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(documents, sents=False):\n",
    "    texts = []\n",
    "    for doc in documents:\n",
    "        tokens = nltk.word_tokenize(doc.lower())\n",
    "        tokens = [t for t in tokens if t not in nltk.corpus.stopwords.words('english')]\n",
    "        tokens = [t for t in tokens if t not in GARBAGE]\n",
    "        texts.append(tokens)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxes =['background-summary-container','background-experience-container',\n",
    "        'background-languages-container', 'background-skills-container',\n",
    "       'background-education-container','background-honors-container']\n",
    "\n",
    "def pull_profile(url):\n",
    "    r = requests.get(url)\n",
    "    content = \"\"\n",
    "    for b in boxes:\n",
    "        try:\n",
    "            divs = BeautifulSoup(r.content).find('div', {'id': b})\n",
    "            for script in divs([\"script\", \"style\"]):\n",
    "                script.extract()    # rip it out   \n",
    "            for d in divs.findAll('div'):\n",
    "                content += \" \".join(d.strings) + \" \"\n",
    "        except:\n",
    "            continue\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html.parser\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Languages   Skills Skills     Education Stanford University PhD,  Electrical Engineering ,  Management Science and Engineering 2005  \\u2013 2010 Activities and Societies:\\xa0 Stanford Triathlon team Harvard University MS,  Computer Science 2003  \\u2013 2005 California Institute of Technology BS,  Electrical Engineering 1999  \\u2013 2003 Captain of the Caltech Flying Team (2001\\u20142003) Activities and Societies:\\xa0 Aero Association of Caltech/JPL Stanford University PhD,  Electrical Engineering ,  Management Science and Engineering 2005  \\u2013 2010 Activities and Societies:\\xa0 Stanford Triathlon team Stanford University PhD,  Electrical Engineering ,  Management Science and Engineering 2005  \\u2013 2010 Activities and Societies:\\xa0 Stanford Triathlon team Stanford University PhD,  Electrical Engineering ,  Management Science and Engineering 2005  \\u2013 2010 Activities and Societies:\\xa0 Stanford Triathlon team Harvard University MS,  Computer Science 2003  \\u2013 2005 Harvard University MS,  Computer Science 2003  \\u2013 2005 Harvard University MS,  Computer Science 2003  \\u2013 2005 California Institute of Technology BS,  Electrical Engineering 1999  \\u2013 2003 Captain of the Caltech Flying Team (2001\\u20142003) Activities and Societies:\\xa0 Aero Association of Caltech/JPL California Institute of Technology BS,  Electrical Engineering 1999  \\u2013 2003 Captain of the Caltech Flying Team (2001\\u20142003) Activities and Societies:\\xa0 Aero Association of Caltech/JPL California Institute of Technology BS,  Electrical Engineering 1999  \\u2013 2003 Captain of the Caltech Flying Team (2001\\u20142003) Activities and Societies:\\xa0 Aero Association of Caltech/JPL Honors & Awards '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_profile('https://www.linkedin.com/in/elaineo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
